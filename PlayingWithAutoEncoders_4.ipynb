{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求めるautoencoderは、最小の特徴量で、なんとか４と９を分離してくれるものである。中間層の要素数が1個でははっきり分離してくれなかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_train_idx = np.logical_or(y_train == 4, y_train == 9)\n",
    "keep_test_idx = np.logical_or(y_test ==4, y_test == 9)\n",
    "\n",
    "x_train = x_train[keep_train_idx]\n",
    "x_test = x_test[keep_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vec = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test_vec = x_test.reshape(x_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは12個に設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 12)                9420      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 784)               10192     \n",
      "=================================================================\n",
      "Total params: 19,612\n",
      "Trainable params: 19,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11791 samples, validate on 1991 samples\n",
      "Epoch 1/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.1392 - acc: 0.0051 - val_loss: 0.0845 - val_acc: 0.0060\n",
      "Epoch 2/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0702 - acc: 0.0084 - val_loss: 0.0571 - val_acc: 0.0095\n",
      "Epoch 3/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0564 - acc: 0.0086 - val_loss: 0.0528 - val_acc: 0.0095\n",
      "Epoch 4/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0538 - acc: 0.0101 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 5/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0532 - acc: 0.0095 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 6/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0531 - acc: 0.0091 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 7/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0530 - acc: 0.0089 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 8/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0530 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 9/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0530 - acc: 0.0098 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 10/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0530 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 11/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 12/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0105 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 13/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0099 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 14/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0102 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 15/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0096 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 16/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 17/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0101 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 18/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 19/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 20/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0104 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 21/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0101 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 22/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0104 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 23/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0104 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 24/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 25/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 26/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 27/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0102 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 28/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 29/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0527 - acc: 0.0098 - val_loss: 0.0518 - val_acc: 0.0095\n",
      "Epoch 30/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0523 - acc: 0.0103 - val_loss: 0.0513 - val_acc: 0.0095\n",
      "Epoch 31/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0519 - acc: 0.0094 - val_loss: 0.0509 - val_acc: 0.0050\n",
      "Epoch 32/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0515 - acc: 0.0090 - val_loss: 0.0504 - val_acc: 0.0050\n",
      "Epoch 33/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0512 - acc: 0.0087 - val_loss: 0.0501 - val_acc: 0.0045\n",
      "Epoch 34/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0509 - acc: 0.0084 - val_loss: 0.0498 - val_acc: 0.0045\n",
      "Epoch 35/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0507 - acc: 0.0083 - val_loss: 0.0495 - val_acc: 0.0045\n",
      "Epoch 36/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0505 - acc: 0.0087 - val_loss: 0.0493 - val_acc: 0.0045\n",
      "Epoch 37/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0504 - acc: 0.0087 - val_loss: 0.0490 - val_acc: 0.0045\n",
      "Epoch 38/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0502 - acc: 0.0100 - val_loss: 0.0488 - val_acc: 0.0080\n",
      "Epoch 39/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0501 - acc: 0.0092 - val_loss: 0.0487 - val_acc: 0.0045\n",
      "Epoch 40/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0500 - acc: 0.0097 - val_loss: 0.0486 - val_acc: 0.0085\n",
      "Epoch 41/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0499 - acc: 0.0093 - val_loss: 0.0484 - val_acc: 0.0080\n",
      "Epoch 42/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0499 - acc: 0.0094 - val_loss: 0.0483 - val_acc: 0.0095\n",
      "Epoch 43/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0498 - acc: 0.0091 - val_loss: 0.0482 - val_acc: 0.0095\n",
      "Epoch 44/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0497 - acc: 0.0095 - val_loss: 0.0480 - val_acc: 0.0095\n",
      "Epoch 45/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0497 - acc: 0.0091 - val_loss: 0.0480 - val_acc: 0.0085\n",
      "Epoch 46/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0497 - acc: 0.0087 - val_loss: 0.0479 - val_acc: 0.0080\n",
      "Epoch 47/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0496 - acc: 0.0090 - val_loss: 0.0479 - val_acc: 0.0095\n",
      "Epoch 48/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0496 - acc: 0.0092 - val_loss: 0.0478 - val_acc: 0.0100\n",
      "Epoch 49/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0496 - acc: 0.0108 - val_loss: 0.0478 - val_acc: 0.0095\n",
      "Epoch 50/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0088 - val_loss: 0.0477 - val_acc: 0.0085\n",
      "Epoch 51/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0097 - val_loss: 0.0477 - val_acc: 0.0090\n",
      "Epoch 52/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0104 - val_loss: 0.0476 - val_acc: 0.0090\n",
      "Epoch 53/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0098 - val_loss: 0.0476 - val_acc: 0.0095\n",
      "Epoch 54/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0092 - val_loss: 0.0476 - val_acc: 0.0105\n",
      "Epoch 55/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0104 - val_loss: 0.0477 - val_acc: 0.0090\n",
      "Epoch 56/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0098 - val_loss: 0.0476 - val_acc: 0.0055\n",
      "Epoch 57/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0495 - acc: 0.0097 - val_loss: 0.0475 - val_acc: 0.0100\n",
      "Epoch 58/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0492 - acc: 0.0099 - val_loss: 0.0471 - val_acc: 0.0095\n",
      "Epoch 59/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0486 - acc: 0.0106 - val_loss: 0.0464 - val_acc: 0.0085\n",
      "Epoch 60/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0480 - acc: 0.0106 - val_loss: 0.0455 - val_acc: 0.0080\n",
      "Epoch 61/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0474 - acc: 0.0097 - val_loss: 0.0450 - val_acc: 0.0095\n",
      "Epoch 62/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0471 - acc: 0.0107 - val_loss: 0.0445 - val_acc: 0.0085\n",
      "Epoch 63/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0468 - acc: 0.0102 - val_loss: 0.0442 - val_acc: 0.0105\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0466 - acc: 0.0096 - val_loss: 0.0437 - val_acc: 0.0121\n",
      "Epoch 65/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0463 - acc: 0.0105 - val_loss: 0.0434 - val_acc: 0.0100\n",
      "Epoch 66/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0462 - acc: 0.0108 - val_loss: 0.0432 - val_acc: 0.0100\n",
      "Epoch 67/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0460 - acc: 0.0098 - val_loss: 0.0430 - val_acc: 0.0105\n",
      "Epoch 68/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0458 - acc: 0.0100 - val_loss: 0.0426 - val_acc: 0.0116\n",
      "Epoch 69/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0456 - acc: 0.0103 - val_loss: 0.0423 - val_acc: 0.0105\n",
      "Epoch 70/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0452 - acc: 0.0099 - val_loss: 0.0421 - val_acc: 0.0095\n",
      "Epoch 71/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0450 - acc: 0.0107 - val_loss: 0.0417 - val_acc: 0.0095\n",
      "Epoch 72/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0447 - acc: 0.0104 - val_loss: 0.0413 - val_acc: 0.0095\n",
      "Epoch 73/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0446 - acc: 0.0102 - val_loss: 0.0411 - val_acc: 0.0095\n",
      "Epoch 74/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0444 - acc: 0.0108 - val_loss: 0.0410 - val_acc: 0.0100\n",
      "Epoch 75/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0442 - acc: 0.0104 - val_loss: 0.0407 - val_acc: 0.0095\n",
      "Epoch 76/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0441 - acc: 0.0097 - val_loss: 0.0405 - val_acc: 0.0090\n",
      "Epoch 77/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0440 - acc: 0.0092 - val_loss: 0.0403 - val_acc: 0.0095\n",
      "Epoch 78/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0439 - acc: 0.0105 - val_loss: 0.0402 - val_acc: 0.0095\n",
      "Epoch 79/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0439 - acc: 0.0109 - val_loss: 0.0401 - val_acc: 0.0100\n",
      "Epoch 80/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0438 - acc: 0.0111 - val_loss: 0.0400 - val_acc: 0.0090\n",
      "Epoch 81/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0437 - acc: 0.0102 - val_loss: 0.0399 - val_acc: 0.0095\n",
      "Epoch 82/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0437 - acc: 0.0099 - val_loss: 0.0397 - val_acc: 0.0095\n",
      "Epoch 83/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0436 - acc: 0.0103 - val_loss: 0.0396 - val_acc: 0.0080\n",
      "Epoch 84/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0435 - acc: 0.0099 - val_loss: 0.0396 - val_acc: 0.0080\n",
      "Epoch 85/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0434 - acc: 0.0110 - val_loss: 0.0394 - val_acc: 0.0095\n",
      "Epoch 86/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0431 - acc: 0.0103 - val_loss: 0.0392 - val_acc: 0.0095\n",
      "Epoch 87/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0430 - acc: 0.0092 - val_loss: 0.0389 - val_acc: 0.0085\n",
      "Epoch 88/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0429 - acc: 0.0103 - val_loss: 0.0387 - val_acc: 0.0090\n",
      "Epoch 89/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0426 - acc: 0.0086 - val_loss: 0.0385 - val_acc: 0.0095\n",
      "Epoch 90/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0426 - acc: 0.0104 - val_loss: 0.0384 - val_acc: 0.0095\n",
      "Epoch 91/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0424 - acc: 0.0090 - val_loss: 0.0382 - val_acc: 0.0085\n",
      "Epoch 92/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0423 - acc: 0.0108 - val_loss: 0.0380 - val_acc: 0.0105\n",
      "Epoch 93/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0423 - acc: 0.0098 - val_loss: 0.0377 - val_acc: 0.0100\n",
      "Epoch 94/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0422 - acc: 0.0089 - val_loss: 0.0376 - val_acc: 0.0105\n",
      "Epoch 95/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0421 - acc: 0.0099 - val_loss: 0.0376 - val_acc: 0.0105\n",
      "Epoch 96/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0421 - acc: 0.0095 - val_loss: 0.0375 - val_acc: 0.0100\n",
      "Epoch 97/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0420 - acc: 0.0103 - val_loss: 0.0375 - val_acc: 0.0100\n",
      "Epoch 98/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0420 - acc: 0.0100 - val_loss: 0.0374 - val_acc: 0.0116\n",
      "Epoch 99/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0103 - val_loss: 0.0376 - val_acc: 0.0105\n",
      "Epoch 100/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0097 - val_loss: 0.0372 - val_acc: 0.0110\n",
      "Epoch 101/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0081 - val_loss: 0.0373 - val_acc: 0.0105\n",
      "Epoch 102/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0419 - acc: 0.0102 - val_loss: 0.0372 - val_acc: 0.0110\n",
      "Epoch 103/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0093 - val_loss: 0.0372 - val_acc: 0.0095\n",
      "Epoch 104/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0086 - val_loss: 0.0371 - val_acc: 0.0095\n",
      "Epoch 105/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0419 - acc: 0.0101 - val_loss: 0.0372 - val_acc: 0.0095\n",
      "Epoch 106/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0417 - acc: 0.0091 - val_loss: 0.0369 - val_acc: 0.0100\n",
      "Epoch 107/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0098 - val_loss: 0.0371 - val_acc: 0.0105\n",
      "Epoch 108/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0419 - acc: 0.0090 - val_loss: 0.0370 - val_acc: 0.0105\n",
      "Epoch 109/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0417 - acc: 0.0099 - val_loss: 0.0372 - val_acc: 0.0100\n",
      "Epoch 110/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0416 - acc: 0.0087 - val_loss: 0.0369 - val_acc: 0.0095\n",
      "Epoch 111/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0418 - acc: 0.0103 - val_loss: 0.0370 - val_acc: 0.0100\n",
      "Epoch 112/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0417 - acc: 0.0087 - val_loss: 0.0370 - val_acc: 0.0100\n",
      "Epoch 113/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0417 - acc: 0.0094 - val_loss: 0.0369 - val_acc: 0.0090\n",
      "Epoch 114/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0087 - val_loss: 0.0369 - val_acc: 0.0095\n",
      "Epoch 115/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0416 - acc: 0.0095 - val_loss: 0.0369 - val_acc: 0.0100\n",
      "Epoch 116/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0084 - val_loss: 0.0366 - val_acc: 0.0110\n",
      "Epoch 117/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0416 - acc: 0.0084 - val_loss: 0.0367 - val_acc: 0.0085\n",
      "Epoch 118/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0416 - acc: 0.0095 - val_loss: 0.0368 - val_acc: 0.0095\n",
      "Epoch 119/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0087 - val_loss: 0.0367 - val_acc: 0.0095\n",
      "Epoch 120/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0417 - acc: 0.0096 - val_loss: 0.0367 - val_acc: 0.0095\n",
      "Epoch 121/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0090 - val_loss: 0.0367 - val_acc: 0.0100\n",
      "Epoch 122/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0087 - val_loss: 0.0367 - val_acc: 0.0095\n",
      "Epoch 123/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0414 - acc: 0.0097 - val_loss: 0.0366 - val_acc: 0.0095\n",
      "Epoch 124/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0414 - acc: 0.0095 - val_loss: 0.0366 - val_acc: 0.0105\n",
      "Epoch 125/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0093 - val_loss: 0.0366 - val_acc: 0.0090\n",
      "Epoch 126/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0414 - acc: 0.0092 - val_loss: 0.0367 - val_acc: 0.0100\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0103 - val_loss: 0.0364 - val_acc: 0.0100\n",
      "Epoch 128/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0414 - acc: 0.0095 - val_loss: 0.0365 - val_acc: 0.0090\n",
      "Epoch 129/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0089 - val_loss: 0.0364 - val_acc: 0.0100\n",
      "Epoch 130/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0415 - acc: 0.0082 - val_loss: 0.0365 - val_acc: 0.0095\n",
      "Epoch 131/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0092 - val_loss: 0.0364 - val_acc: 0.0090\n",
      "Epoch 132/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0103 - val_loss: 0.0364 - val_acc: 0.0100\n",
      "Epoch 133/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0098 - val_loss: 0.0364 - val_acc: 0.0100\n",
      "Epoch 134/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0089 - val_loss: 0.0364 - val_acc: 0.0090\n",
      "Epoch 135/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0086 - val_loss: 0.0366 - val_acc: 0.0090\n",
      "Epoch 136/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0087 - val_loss: 0.0365 - val_acc: 0.0100\n",
      "Epoch 137/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0092 - val_loss: 0.0363 - val_acc: 0.0095\n",
      "Epoch 138/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0093 - val_loss: 0.0364 - val_acc: 0.0095\n",
      "Epoch 139/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0090 - val_loss: 0.0363 - val_acc: 0.0100\n",
      "Epoch 140/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0098 - val_loss: 0.0364 - val_acc: 0.0100\n",
      "Epoch 141/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0098 - val_loss: 0.0366 - val_acc: 0.0105\n",
      "Epoch 142/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0096 - val_loss: 0.0361 - val_acc: 0.0095\n",
      "Epoch 143/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0093 - val_loss: 0.0362 - val_acc: 0.0090\n",
      "Epoch 144/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0414 - acc: 0.0098 - val_loss: 0.0364 - val_acc: 0.0105\n",
      "Epoch 145/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0091 - val_loss: 0.0363 - val_acc: 0.0100\n",
      "Epoch 146/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0413 - acc: 0.0090 - val_loss: 0.0364 - val_acc: 0.0095\n",
      "Epoch 147/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0079 - val_loss: 0.0364 - val_acc: 0.0095\n",
      "Epoch 148/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0075 - val_loss: 0.0362 - val_acc: 0.0095\n",
      "Epoch 149/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0082 - val_loss: 0.0365 - val_acc: 0.0095\n",
      "Epoch 150/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0090 - val_loss: 0.0363 - val_acc: 0.0100\n",
      "Epoch 151/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0094 - val_loss: 0.0364 - val_acc: 0.0095\n",
      "Epoch 152/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0092 - val_loss: 0.0363 - val_acc: 0.0090\n",
      "Epoch 153/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0095 - val_loss: 0.0362 - val_acc: 0.0105\n",
      "Epoch 154/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0087 - val_loss: 0.0362 - val_acc: 0.0095\n",
      "Epoch 155/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0074 - val_loss: 0.0361 - val_acc: 0.0105\n",
      "Epoch 156/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0086 - val_loss: 0.0362 - val_acc: 0.0095\n",
      "Epoch 157/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0087 - val_loss: 0.0363 - val_acc: 0.0105\n",
      "Epoch 158/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0082 - val_loss: 0.0362 - val_acc: 0.0100\n",
      "Epoch 159/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0086 - val_loss: 0.0361 - val_acc: 0.0100\n",
      "Epoch 160/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0083 - val_loss: 0.0362 - val_acc: 0.0110\n",
      "Epoch 161/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0086 - val_loss: 0.0362 - val_acc: 0.0100\n",
      "Epoch 162/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0089 - val_loss: 0.0363 - val_acc: 0.0085\n",
      "Epoch 163/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0081 - val_loss: 0.0362 - val_acc: 0.0105\n",
      "Epoch 164/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0092 - val_loss: 0.0361 - val_acc: 0.0090\n",
      "Epoch 165/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0084 - val_loss: 0.0362 - val_acc: 0.0110\n",
      "Epoch 166/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0086 - val_loss: 0.0361 - val_acc: 0.0116\n",
      "Epoch 167/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0085 - val_loss: 0.0360 - val_acc: 0.0110\n",
      "Epoch 168/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0091 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 169/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0412 - acc: 0.0090 - val_loss: 0.0362 - val_acc: 0.0105\n",
      "Epoch 170/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0087 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 171/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0082 - val_loss: 0.0361 - val_acc: 0.0105\n",
      "Epoch 172/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0088 - val_loss: 0.0362 - val_acc: 0.0105\n",
      "Epoch 173/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0075 - val_loss: 0.0360 - val_acc: 0.0095\n",
      "Epoch 174/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0087 - val_loss: 0.0361 - val_acc: 0.0095\n",
      "Epoch 175/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0411 - acc: 0.0085 - val_loss: 0.0362 - val_acc: 0.0105\n",
      "Epoch 176/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0087 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 177/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0081 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 178/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0085 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 179/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0071 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 180/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0408 - acc: 0.0092 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 181/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0075 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 182/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0082 - val_loss: 0.0360 - val_acc: 0.0110\n",
      "Epoch 183/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0084 - val_loss: 0.0360 - val_acc: 0.0121\n",
      "Epoch 184/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0087 - val_loss: 0.0359 - val_acc: 0.0105\n",
      "Epoch 185/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0075 - val_loss: 0.0359 - val_acc: 0.0100\n",
      "Epoch 186/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0087 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 187/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0408 - acc: 0.0090 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 188/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0074 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 189/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0081 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0085 - val_loss: 0.0358 - val_acc: 0.0090\n",
      "Epoch 191/200\n",
      "11791/11791 [==============================] - ETA: 0s - loss: 0.0408 - acc: 0.008 - 0s - loss: 0.0408 - acc: 0.0084 - val_loss: 0.0360 - val_acc: 0.0100\n",
      "Epoch 192/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0086 - val_loss: 0.0359 - val_acc: 0.0100\n",
      "Epoch 193/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0410 - acc: 0.0075 - val_loss: 0.0360 - val_acc: 0.0105\n",
      "Epoch 194/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0082 - val_loss: 0.0362 - val_acc: 0.0095\n",
      "Epoch 195/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0075 - val_loss: 0.0360 - val_acc: 0.0095\n",
      "Epoch 196/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0079 - val_loss: 0.0358 - val_acc: 0.0100\n",
      "Epoch 197/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0080 - val_loss: 0.0358 - val_acc: 0.0100\n",
      "Epoch 198/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0090 - val_loss: 0.0359 - val_acc: 0.0105\n",
      "Epoch 199/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0408 - acc: 0.0085 - val_loss: 0.0358 - val_acc: 0.0100\n",
      "Epoch 200/200\n",
      "11791/11791 [==============================] - 0s - loss: 0.0409 - acc: 0.0073 - val_loss: 0.0358 - val_acc: 0.0095\n",
      "Test loss: 0.0358422875764\n",
      "Test accuracy: 0.0095429432446\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_vec, x_train_vec,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_vec, x_test_vec))\n",
    "score = model.evaluate(x_test_vec, x_test_vec, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中間要素数がきわどくなると、ロスがなかなか落ちにくくなるが、今日はこれくらいのエポック数で勘弁してやる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa4b84ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    predicted = model.predict(x_train_vec[i:i+1]).reshape((28,28))\n",
    "    plt.imshow(predicted)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "４と９の違いは右上の部分が開いているかどうかなのだが、大局的な形状については再現しているものの、右上の部分をあまり区別してくれていない。たぶん要素数のみによる最適化はこのへんが限界なのだろう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
