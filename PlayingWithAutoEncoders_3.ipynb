{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パーセプトロン1個を1ビットと考えれば、究極的には中間層が1個あれば、４と９を分離するには十分なはずである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 300\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_train_idx = np.logical_or(y_train == 4, y_train == 9)\n",
    "keep_test_idx = np.logical_or(y_test ==4, y_test == 9)\n",
    "\n",
    "x_train = x_train[keep_train_idx]\n",
    "x_test = x_test[keep_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vec = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test_vec = x_test.reshape(x_test.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1)                 785       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 784)               1568      \n",
      "=================================================================\n",
      "Total params: 2,353\n",
      "Trainable params: 2,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11791 samples, validate on 1991 samples\n",
      "Epoch 1/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.2115 - acc: 0.0032 - val_loss: 0.1940 - val_acc: 0.0030\n",
      "Epoch 2/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.1802 - acc: 0.0029 - val_loss: 0.1650 - val_acc: 0.0030\n",
      "Epoch 3/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.1540 - acc: 0.0030 - val_loss: 0.1406 - val_acc: 0.0060\n",
      "Epoch 4/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.1337 - acc: 0.0062 - val_loss: 0.1204 - val_acc: 0.0060\n",
      "Epoch 5/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.1167 - acc: 0.0068 - val_loss: 0.1041 - val_acc: 0.0060\n",
      "Epoch 6/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.1036 - acc: 0.0076 - val_loss: 0.0912 - val_acc: 0.0060\n",
      "Epoch 7/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0937 - acc: 0.0079 - val_loss: 0.0811 - val_acc: 0.0095\n",
      "Epoch 8/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0851 - acc: 0.0103 - val_loss: 0.0734 - val_acc: 0.0095\n",
      "Epoch 9/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0793 - acc: 0.0103 - val_loss: 0.0676 - val_acc: 0.0095\n",
      "Epoch 10/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0744 - acc: 0.0103 - val_loss: 0.0633 - val_acc: 0.0095\n",
      "Epoch 11/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0708 - acc: 0.0103 - val_loss: 0.0601 - val_acc: 0.0095\n",
      "Epoch 12/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0678 - acc: 0.0103 - val_loss: 0.0578 - val_acc: 0.0095\n",
      "Epoch 13/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0650 - acc: 0.0103 - val_loss: 0.0561 - val_acc: 0.00950.0\n",
      "Epoch 14/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0631 - acc: 0.0103 - val_loss: 0.0549 - val_acc: 0.0095\n",
      "Epoch 15/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0615 - acc: 0.0103 - val_loss: 0.0541 - val_acc: 0.0095\n",
      "Epoch 16/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0602 - acc: 0.0103 - val_loss: 0.0534 - val_acc: 0.0095\n",
      "Epoch 17/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0590 - acc: 0.0103 - val_loss: 0.0530 - val_acc: 0.0095\n",
      "Epoch 18/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0580 - acc: 0.0103 - val_loss: 0.0527 - val_acc: 0.0095\n",
      "Epoch 19/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0571 - acc: 0.0103 - val_loss: 0.0525 - val_acc: 0.0095\n",
      "Epoch 20/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0565 - acc: 0.0103 - val_loss: 0.0524 - val_acc: 0.0095\n",
      "Epoch 21/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0559 - acc: 0.0103 - val_loss: 0.0523 - val_acc: 0.0095\n",
      "Epoch 22/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0554 - acc: 0.0103 - val_loss: 0.0522 - val_acc: 0.0095\n",
      "Epoch 23/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0549 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 24/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0546 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 25/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0543 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 26/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0540 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 27/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0538 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 28/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0536 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 29/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0535 - acc: 0.0103 - val_loss: 0.0521 - val_acc: 0.0095\n",
      "Epoch 30/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0533 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 31/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0532 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 32/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0531 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 33/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0531 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 34/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0530 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 35/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 36/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0529 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 37/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 38/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 39/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0528 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 40/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 41/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 42/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 43/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 44/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 45/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 46/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 47/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 48/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 49/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0527 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 50/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 51/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 52/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 53/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 54/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 55/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 56/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 57/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 58/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 59/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 60/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 61/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 62/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 63/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 65/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 66/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 67/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 68/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 69/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 70/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 71/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 72/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 73/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 74/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 75/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 76/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 77/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 78/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 79/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 80/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 81/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 82/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 83/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 84/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 85/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 86/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 87/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 88/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 89/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 90/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 91/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 92/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 93/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 94/300\n",
      "11791/11791 [==============================] - 1s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 95/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 96/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 97/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 98/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 99/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 100/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 101/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 102/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 103/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 104/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 105/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 106/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 107/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 108/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 109/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 110/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 111/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 112/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 113/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 114/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 115/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 116/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 117/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 118/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 119/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 120/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 121/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 122/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 123/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 124/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 125/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 126/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 128/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 129/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 130/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 131/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 132/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 133/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 134/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 135/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 136/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 137/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 138/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 139/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 140/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 141/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 142/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 143/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 144/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 145/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 146/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 147/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 148/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 149/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 150/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 151/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 152/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 153/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 154/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 155/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 156/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 157/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 158/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 159/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 160/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 161/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 162/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 163/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 164/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 165/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 166/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 167/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 168/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 169/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 170/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 171/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 172/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 173/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 174/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 175/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 176/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 177/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 178/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 179/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 180/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 181/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 182/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 183/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 184/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 185/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 186/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 187/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 188/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 189/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 191/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 192/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 193/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 194/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 195/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 196/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 197/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 198/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 199/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 200/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 201/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 202/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 203/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 204/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 205/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 206/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 207/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 208/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 209/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 210/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 211/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 212/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 213/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 214/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 215/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 216/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 217/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 218/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 219/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 220/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 221/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 222/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 223/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 224/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 225/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 226/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 227/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 228/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 229/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 230/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 231/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 232/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 233/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 234/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 235/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 236/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 237/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 238/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 239/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 240/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 241/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 242/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 243/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 244/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 245/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 246/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 247/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 248/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 249/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 250/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 251/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 252/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 254/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 255/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 256/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 257/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 258/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 259/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 260/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 261/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 262/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 263/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 264/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 265/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 266/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 267/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 268/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 269/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 270/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 271/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 272/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 273/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 274/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 275/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 276/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 277/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 278/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 279/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 280/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 281/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 282/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 283/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 284/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 285/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 286/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 287/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 288/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 289/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 290/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 291/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 292/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 293/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 294/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 295/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 296/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 297/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 298/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 299/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Epoch 300/300\n",
      "11791/11791 [==============================] - 0s - loss: 0.0526 - acc: 0.0103 - val_loss: 0.0520 - val_acc: 0.0095\n",
      "Test loss: 0.0520275568955\n",
      "Test accuracy: 0.0095429432446\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_vec, x_train_vec,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_vec, x_test_vec))\n",
    "score = model.evaluate(x_test_vec, x_test_vec, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この場合、70エポックぐらいですでに改善が止まってしまっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKvD/AAxQMAqmOCiuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2061faa2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    predicted = model.predict(x_train_vec[i:i+1]).reshape((28,28))\n",
    "    plt.imshow(predicted)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "４と９を分離してくれなくなってしまった。多数の入力をほとんど同じ1パターンに出力してしまうという意味で、さっきとは別の失敗モードである。とはいえ得たものはある。４または９の大局的な形については把握してくれたようだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
